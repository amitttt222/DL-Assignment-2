{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import os\n# from PIL import Image\n# import numpy as np\n\n# def load_data(data_dir):\n#     images = []\n#     labels = []\n#     classes = os.listdir(data_dir)\n#     for cls in classes:\n#         cls_path = os.path.join(data_dir, cls)\n#         if os.path.isdir(cls_path):\n#             cls_images = os.listdir(cls_path)\n#             for img_name in cls_images:\n#                 img_path = os.path.join(cls_path, img_name)\n#                 img = Image.open(img_path).resize((224, 224))\n#                 img = np.array(img) / 255.0\n#                 images.append(img)\n#                 labels.append(cls)\n#     return np.array(images), np.array(labels)\n\n\n# data_dir = '/kaggle/input/inaturalist12k/Data/inaturalist_12K'\n\n# train_dir = os.path.join(data_dir, 'train')\n# X_train, y_train = load_data(train_dir)\n\n# val_dir = os.path.join(data_dir, 'val')\n# X_val, y_val = load_data(val_dir)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-08T14:53:51.721586Z","iopub.execute_input":"2023-04-08T14:53:51.722367Z","iopub.status.idle":"2023-04-08T14:53:51.727606Z","shell.execute_reply.started":"2023-04-08T14:53:51.722326Z","shell.execute_reply":"2023-04-08T14:53:51.726248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(os.listdir('/kaggle/input'))","metadata":{"execution":{"iopub.status.busy":"2023-04-08T14:53:58.079943Z","iopub.execute_input":"2023-04-08T14:53:58.080324Z","iopub.status.idle":"2023-04-08T14:53:58.085170Z","shell.execute_reply.started":"2023-04-08T14:53:58.080289Z","shell.execute_reply":"2023-04-08T14:53:58.083970Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom PIL import Image\nimport numpy as np\n#import tensorflow as tf\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import random_split\nimport torch\nimport wandb\nwandb.login(key='e595ff5b95c353a42c4bd1f35b70856d4309ef00')\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ndata_dir = '/kaggle/input/inaturalist12k/Data/inaturalist_12K'\n#-------------------------------------------------------------------------------------------------------\n# def get_transforms(data_augmentation):\n#     if data_augmentation==\"yes\":\n#         transform = transforms.Compose([\n#             transforms.RandomHorizontalFlip(p=0.5),\n#             transforms.RandomVerticalFlip(p=0.5),\n#             transforms.RandomRotation(degrees=30),\n#             transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n#             transforms.Resize((256,256)),\n#             transforms.ToTensor()\n#         ])\n#     else:\n#         transform = transforms.Compose([\n#             transforms.Resize((256,256)),\n#             transforms.ToTensor()\n#         ])\n#     return transform\n\n# transform = transforms.Compose([transforms.Resize((256,256)),transforms.ToTensor()])\n# train_dataset=torchvision.datasets.ImageFolder(root=data_dir+'/train',transform=get_transforms(\"yes\"))\n# test_dataset=torchvision.datasets.ImageFolder(root=data_dir+'/val',transform=transform)\n\n# val_size = int(len(train_dataset) * 0.2)\n# train_size = len(train_dataset) - val_size\n\n# train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n\n# train_loader=DataLoader(train_dataset,batch_size=16,shuffle=True)\n# val_loader=DataLoader(val_dataset,batch_size=16,shuffle=False)\n# test_loader=DataLoader(test_dataset,batch_size=16,shuffle=False)\n#--------------------------------------------------------------------------------------------------------","metadata":{"execution":{"iopub.status.busy":"2023-04-10T23:32:23.502881Z","iopub.execute_input":"2023-04-10T23:32:23.503373Z","iopub.status.idle":"2023-04-10T23:32:26.973201Z","shell.execute_reply.started":"2023-04-10T23:32:23.503329Z","shell.execute_reply":"2023-04-10T23:32:26.971949Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.optim as optim\n\nimport torch.nn.functional as F\nclass Mish(nn.Module):\n    def __init__(self):\n        super().__init__()\n    def forward(self, x):\n        return x * torch.tanh(F.softplus(x))\n# Define the CNN model architecture\nclass CNN(nn.Module):\n    def __init__(self, num_filters, filter_size, activation_fn, filter_org, batch_norm, dropout,num_neuron_fc,filter_size_org):\n        super(CNN, self).__init__()\n        if(activation_fn==\"ReLU\"):\n            activation_fn=nn.ReLU\n        if(activation_fn==\"GELU\"):\n            activation_fn=nn.GELU\n        if(activation_fn==\"SiLU\"):\n            activation_fn=nn.SiLU\n        if(activation_fn==\"Mish\"):\n            activation_fn=Mish\n        if(filter_org==\"double\"):\n            filter_org=[1,2,2,2,2]\n        if(filter_org==\"same\"):\n            filter_org=[1,1,1,1,1]\n        if(filter_org==\"half\"):\n            filter_org=[1,0.5,0.5,0.5,0.5]\n        if(filter_size_org=='same'):\n            filter_size_org=[1,1,1,1,1]\n        if(filter_size_org==\"double\"):\n            filter_size_org=[1,2,2,2,2]\n        if(filter_size_org==\"half\"):\n            filter_size_org=[1,0.5,0.5,0.5,0.5]\n        layers = []\n        in_channels = 3\n        w=256\n        for i, f in enumerate(filter_org):\n            out_channels = int(num_filters * f)\n            filter_size1 = int(filter_size*filter_size_org[i])\n            #calculate feature map dimension\n            w=int((w-filter_size1+(2*1))+1)\n            w=int(((w-2)//2)+1)\n            #ends\n            layers.append(nn.Conv2d(int(in_channels), int(out_channels), int(filter_size1), padding=1))\n            if batch_norm:\n                layers.append(nn.BatchNorm2d(out_channels))\n            layers.append(activation_fn())\n            layers.append(nn.MaxPool2d(2))\n            if dropout > 0:\n                layers.append(nn.Dropout(dropout))\n            in_channels = out_channels\n        #print(w)\n        self.cnn = nn.Sequential(*layers)      \n        self.fc1 = nn.Linear(int(out_channels) * w * w, num_neuron_fc)\n        self.fc2 = nn.Linear(num_neuron_fc, 10)\n\n    def forward(self, x):\n        x = self.cnn(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc1(x)\n        x = self.fc2(x)\n        return x\n\n\n\n#------------------------------------------------------------------------------------------------------\nsweep_config = {\n    'method': 'random', #grid, random,#bayes\n    'name' : 'Random_sweep_cross_entropy',\n    'metric': {\n      'name': 'valid accuracy',\n      'goal': 'maximize'  \n    },\n    'parameters': {\n        'num_filters': {\n            'values': [32,64,96]\n        },\n        'filter_size':{\n            'values':[3,5,7,2]\n        },\n         'activation_fn':{\n            'values':[\"Mish\",\"ReLU\",\"GELU\",\"SiLU\"]\n        },\n        'filter_org':{\n            'values':[\"same\",\"double\",\"half\"]\n        },\n         'filter_size_org':{\n            'values':[\"same\",\"double\"]\n        },\n         'batch_norm': {\n            'values': [True,False]\n        },\n        'dropout': {\n            'values': [0.3,0.2]\n        },\n         'num_neuron_fc':{\n            'values':[10,20]\n        },\n        'data_augmentation': {\n            'values': [\"no\",\"yes\"]\n        }, \n#         'loss': {\n#             'values': ['entropy_loss']\n#         }, \n        \n        \n    }\n}\n\nsweep_id = wandb.sweep(sweep=sweep_config, project='DL_Assign_2')\nfrom types import SimpleNamespace\ndef main():\n    with wandb.init() as run:\n        params={}\n        params=dict(wandb.config)\n        params=SimpleNamespace(**params)\n        run_name=\"num_filter_\"+str(wandb.config.num_filters)+\"-filter_size_\"+str(wandb.config.filter_size)+\"-activation_fn_\"+wandb.config.activation_fn\\\n                + \"-filter_org\"+wandb.config.filter_org+\"-filter_size_org\"+wandb.config.filter_size_org+\"-batch_norm\"+str(wandb.config.batch_norm)\\\n                + \"-dropout\"+str(wandb.config.dropout)+\"num_neuron_fc\"+str(wandb.config.num_neuron_fc)+\"-data_augmentation\"+wandb.config.data_augmentation\n        wandb.run.name=run_name\n        \n        #data augmentation function starts\n        def get_transforms(data_augmentation):\n            if data_augmentation==\"yes\":\n                transform = transforms.Compose([\n                    transforms.RandomHorizontalFlip(p=0.5),\n                    transforms.RandomVerticalFlip(p=0.5),\n                    transforms.RandomRotation(degrees=30),\n                    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n                    transforms.Resize((256,256)),\n                    transforms.ToTensor()\n                ])\n            else:\n                transform = transforms.Compose([\n                    transforms.Resize((256,256)),\n                    transforms.ToTensor()\n                ])\n            return transform\n        #data augmentation function ends\n        \n        #transform and splitting data starts\n        transform = transforms.Compose([transforms.Resize((256,256)),transforms.ToTensor()])\n        train_dataset=torchvision.datasets.ImageFolder(root=data_dir+'/train',transform=get_transforms(wandb.config.data_augmentation))\n        test_dataset=torchvision.datasets.ImageFolder(root=data_dir+'/val',transform=transform)\n\n        val_size = int(len(train_dataset) * 0.2)\n        train_size = len(train_dataset) - val_size\n\n        train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n\n        train_loader=DataLoader(train_dataset,batch_size=64,shuffle=True)\n        val_loader=DataLoader(val_dataset,batch_size=64,shuffle=False)\n        test_loader=DataLoader(test_dataset,batch_size=64,shuffle=False)\n        #transform and splitting data ends\n        \n        # Initialize the model\n        model = CNN(params.num_filters, params.filter_size, params.activation_fn, params.filter_org, params.batch_norm, params.dropout, params.num_neuron_fc,params.filter_size_org).to(device)\n\n        # Define the loss function and optimizer\n        criterion = nn.CrossEntropyLoss()\n        optimizer = optim.Adam(model.parameters(), lr=0.0001)\n\n        # Train the model\n        num_epochs = 10\n        for epoch in range(num_epochs):\n            model.train()\n            for batch_idx, (data, target) in enumerate(train_loader):\n                data, target = data.to(device), target.to(device)# Move data and target to the device\n                optimizer.zero_grad()\n                output = model(data)\n                loss = criterion(output, target)\n                loss.backward()\n                optimizer.step()\n\n            # Evaluate the model on train_loader\n            model.eval()\n            train_correct = 0\n            train_total = 0\n            train_loss = 0.0\n            with torch.no_grad():\n                for data, target in train_loader:\n                    data, target = data.to(device), target.to(device)# Move data and target to the device\n                    output = model(data)\n                    loss = criterion(output, target)\n                    train_loss += loss.item()\n                    _, predicted = torch.max(output.data, 1)\n                    train_total += target.size(0)\n                    train_correct += (predicted == target).sum().item()\n\n            train_accuracy = 100 * train_correct/train_total\n            train_loss /= len(train_loader)\n\n            # Set model to evaluation mode\n            model.eval()\n            val_loss = 0.0\n            correct = 0\n            total = 0\n            with torch.no_grad():\n                for batch_idx, (data, target) in enumerate(val_loader):\n                    data, target = data.to(device), target.to(device)# Move data and target to the device\n                    output = model(data)\n                    loss = criterion(output, target)\n                    val_loss += loss.item()\n                    _, predicted = torch.max(output.data, 1)\n                    total += target.size(0)\n                    correct += (predicted == target).sum().item()\n\n            # Calculate validation metrics\n            val_loss /= len(val_loader)\n            val_accuracy = 100 * correct / total\n\n            # Print metrics for current epoch\n            #print('Epoch: {} \\t Training Loss: {:.6f}\n            print(\"epoch\",epoch)\n            print('Training Loss: {:.6f} \\t Training Accuracy: {:.6f}'.format(train_loss, train_accuracy))\n            print('Validation Loss: {:.6f} \\t Validation Accuracy: {:.6f}'.format(val_loss, val_accuracy))\n            wandb.log({'train loss':train_loss,'train accuracy':train_accuracy,'valid loss':val_loss,'valid accuracy':val_accuracy})\n#         input_size=784\n#         output_size=10\n#         obj=neural_network(input_size,output_size,params)\n#         obj.predict()\n\n    \nwandb.agent(sweep_id, function=main,count=35)\n\n# #----------------------------------------------------------------------------------------------------\n\n\n# #Define the model hyperparameters\n# num_filters = 96\n# filter_size = 5\n# activation_fn = \"ReLU\"\n# filter_org = \"same\"\n# filter_size_org=\"double\" # extra added\n# batch_norm = False\n# dropout = 0.3\n# num_neuron_fc=10\n\n\n# # Initialize the model\n# model = CNN(num_filters, filter_size, activation_fn, filter_org, batch_norm, dropout, num_neuron_fc,filter_size_org).to(device)\n\n# # Define the loss function and optimizer\n# criterion = nn.CrossEntropyLoss()\n# optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# # Train the model\n# num_epochs = 1\n# for epoch in range(num_epochs):\n#     model.train()\n#     for batch_idx, (data, target) in enumerate(train_loader):\n#         data, target = data.to(device), target.to(device)# Move data and target to the device\n#         optimizer.zero_grad()\n#         output = model(data)\n#         loss = criterion(output, target)\n#         loss.backward()\n#         optimizer.step()\n    \n#     # Evaluate the model on train_loader\n#     model.eval()\n#     train_correct = 0\n#     train_total = 0\n#     train_loss = 0.0\n#     with torch.no_grad():\n#         for data, target in train_loader:\n#             data, target = data.to(device), target.to(device)# Move data and target to the device\n#             output = model(data)\n#             loss = criterion(output, target)\n#             train_loss += loss.item()\n#             _, predicted = torch.max(output.data, 1)\n#             train_total += target.size(0)\n#             train_correct += (predicted == target).sum().item()\n\n#     train_accuracy = 100 * train_correct/train_total\n#     train_loss /= len(train_loader)\n    \n#     # Set model to evaluation mode\n#     model.eval()\n#     val_loss = 0.0\n#     correct = 0\n#     total = 0\n#     with torch.no_grad():\n#         for batch_idx, (data, target) in enumerate(val_loader):\n#             data, target = data.to(device), target.to(device)# Move data and target to the device\n#             output = model(data)\n#             loss = criterion(output, target)\n#             val_loss += loss.item()\n#             _, predicted = torch.max(output.data, 1)\n#             total += target.size(0)\n#             correct += (predicted == target).sum().item()\n            \n#     # Calculate validation metrics\n#     val_loss /= len(val_loader)\n#     val_accuracy = 100 * correct / total\n    \n#     # Print metrics for current epoch\n#     #print('Epoch: {} \\t Training Loss: {:.6f}\n#     print(\"epoch\",epoch)\n          \n#     print('Training Loss: {:.6f} \\t Training Accuracy: {:.6f}'.format(train_loss, train_accuracy))\n#     print('Validation Loss: {:.6f} \\t Validation Accuracy: {:.6f}'.format(val_loss, val_accuracy))\n\n\n\n\n# #------------------------------------------------------------------------------------------\n    \n    \n    \n    \n    \n#     train_loss = 0.0\n#     for batch_idx, (data, target) in enumerate(train_loader): \n#         data, target = data.to(device), target.to(device)# Move data and target to the device\n#         optimizer.zero_grad()\n#         output = model(data)\n#         loss = criterion(output, target)\n#         loss.backward()\n#         optimizer.step()\n#         train_loss += loss.item()\n\n#     print('Epoch: {} \\t Training Loss: {:.6f}'.format(epoch+1, train_loss/len(train_loader)))\n    \n#     # Evaluate the model on train_loader\n#     model.eval()\n#     train_correct = 0\n#     train_total = 0\n#     train_loss = 0.0\n#     with torch.no_grad():\n#         for data, target in train_loader:\n#             output = model(data)\n#             loss = criterion(output, target)\n#             train_loss += loss.item()\n#             _, predicted = torch.max(output.data, 1)\n#             train_total += target.size(0)\n#             train_correct += (predicted == target).sum().item()\n\n#     train_accuracy = train_correct/train_total\n#     train_loss /= len(train_loader)\n\n#     # Evaluate the model on val_loader\n#     model.eval()\n#     val_correct = 0\n#     val_total = 0\n#     val_loss = 0.0\n#     with torch.no_grad():\n#         for data, target in val_loader:\n#             output = model(data)\n#             loss = criterion(output, target)\n#             val_loss += loss.item()\n#             _, predicted = torch.max(output.data, 1)\n#             val_total += target.size(0)\n#             val_correct += (predicted == target).sum().item()\n\n#     val_accuracy = val_correct/val_total\n#     val_loss /= len(val_loader)\n\n#     print('Training Loss: {:.6f} \\t Training Accuracy: {:.6f}'.format(train_loss, train_accuracy))\n#     print('Validation Loss: {:.6f} \\t Validation Accuracy: {:.6f}'.format(val_loss, val_accuracy))\n\n","metadata":{"execution":{"iopub.status.busy":"2023-04-10T23:32:29.590012Z","iopub.execute_input":"2023-04-10T23:32:29.590400Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"name":"stdout","text":"Create sweep with ID: 6589nodc\nSweep URL: https://wandb.ai/cs22m010/DL_Assign_2/sweeps/6589nodc\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ltampi7m with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_fn: ReLU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_augmentation: yes\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_org: same\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size_org: same\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_neuron_fc: 20\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs22m010\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.14.2 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.14.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230410_233308-ltampi7m</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs22m010/DL_Assign_2/runs/ltampi7m' target=\"_blank\">clear-sweep-1</a></strong> to <a href='https://wandb.ai/cs22m010/DL_Assign_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs22m010/DL_Assign_2/sweeps/6589nodc' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2/sweeps/6589nodc</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs22m010/DL_Assign_2' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs22m010/DL_Assign_2/sweeps/6589nodc' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2/sweeps/6589nodc</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs22m010/DL_Assign_2/runs/ltampi7m' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2/runs/ltampi7m</a>"},"metadata":{}},{"name":"stdout","text":"epoch 0\nTraining Loss: 2.259961 \t Training Accuracy: 16.312500\nValidation Loss: 2.254923 \t Validation Accuracy: 17.208604\nepoch 1\nTraining Loss: 2.248382 \t Training Accuracy: 17.162500\nValidation Loss: 2.249766 \t Validation Accuracy: 17.658829\nepoch 2\nTraining Loss: 2.112368 \t Training Accuracy: 23.287500\nValidation Loss: 2.117434 \t Validation Accuracy: 24.262131\nepoch 3\nTraining Loss: 2.075200 \t Training Accuracy: 24.637500\nValidation Loss: 2.076456 \t Validation Accuracy: 24.962481\nepoch 4\nTraining Loss: 2.071518 \t Training Accuracy: 25.800000\nValidation Loss: 2.079660 \t Validation Accuracy: 24.912456\nepoch 5\nTraining Loss: 2.046052 \t Training Accuracy: 26.437500\nValidation Loss: 2.057725 \t Validation Accuracy: 26.263132\nepoch 6\nTraining Loss: 1.978429 \t Training Accuracy: 29.312500\nValidation Loss: 2.002502 \t Validation Accuracy: 29.414707\nepoch 7\nTraining Loss: 1.927699 \t Training Accuracy: 32.062500\nValidation Loss: 1.971180 \t Validation Accuracy: 29.764882\nepoch 8\nTraining Loss: 1.964369 \t Training Accuracy: 29.737500\nValidation Loss: 2.004898 \t Validation Accuracy: 27.363682\nepoch 9\nTraining Loss: 1.915234 \t Training Accuracy: 33.025000\nValidation Loss: 1.967880 \t Validation Accuracy: 29.614807\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train accuracy</td><td>▁▁▄▄▅▅▆█▇█</td></tr><tr><td>train loss</td><td>██▅▄▄▄▂▁▂▁</td></tr><tr><td>valid accuracy</td><td>▁▁▅▅▅▆██▇█</td></tr><tr><td>valid loss</td><td>██▅▄▄▃▂▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train accuracy</td><td>33.025</td></tr><tr><td>train loss</td><td>1.91523</td></tr><tr><td>valid accuracy</td><td>29.61481</td></tr><tr><td>valid loss</td><td>1.96788</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">clear-sweep-1</strong> at: <a href='https://wandb.ai/cs22m010/DL_Assign_2/runs/ltampi7m' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2/runs/ltampi7m</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20230410_233308-ltampi7m/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ynjnx1a3 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_fn: GELU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_augmentation: yes\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_org: double\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size_org: double\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_neuron_fc: 20\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.14.2 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.14.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230411_002925-ynjnx1a3</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs22m010/DL_Assign_2/runs/ynjnx1a3' target=\"_blank\">laced-sweep-2</a></strong> to <a href='https://wandb.ai/cs22m010/DL_Assign_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs22m010/DL_Assign_2/sweeps/6589nodc' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2/sweeps/6589nodc</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs22m010/DL_Assign_2' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs22m010/DL_Assign_2/sweeps/6589nodc' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2/sweeps/6589nodc</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs22m010/DL_Assign_2/runs/ynjnx1a3' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2/runs/ynjnx1a3</a>"},"metadata":{}},{"name":"stdout","text":"epoch 0\nTraining Loss: 2.041260 \t Training Accuracy: 27.325000\nValidation Loss: 2.097057 \t Validation Accuracy: 25.612806\nepoch 1\nTraining Loss: 1.931653 \t Training Accuracy: 31.175000\nValidation Loss: 1.992649 \t Validation Accuracy: 29.314657\nepoch 2\nTraining Loss: 1.952715 \t Training Accuracy: 30.425000\nValidation Loss: 2.040322 \t Validation Accuracy: 26.863432\nepoch 3\nTraining Loss: 1.825889 \t Training Accuracy: 34.925000\nValidation Loss: 1.933528 \t Validation Accuracy: 31.515758\nepoch 4\nTraining Loss: 1.799459 \t Training Accuracy: 36.662500\nValidation Loss: 1.924658 \t Validation Accuracy: 32.066033\nepoch 5\nTraining Loss: 1.802540 \t Training Accuracy: 36.350000\nValidation Loss: 1.955099 \t Validation Accuracy: 31.665833\nepoch 6\nTraining Loss: 1.807917 \t Training Accuracy: 35.300000\nValidation Loss: 1.970471 \t Validation Accuracy: 28.564282\nepoch 7\nTraining Loss: 1.626105 \t Training Accuracy: 43.212500\nValidation Loss: 1.862208 \t Validation Accuracy: 35.317659\nepoch 8\nTraining Loss: 1.575985 \t Training Accuracy: 45.350000\nValidation Loss: 1.840276 \t Validation Accuracy: 36.018009\nepoch 9\nTraining Loss: 1.609423 \t Training Accuracy: 43.000000\nValidation Loss: 1.925221 \t Validation Accuracy: 34.917459\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4555f1d5663d4a4bbf6ce7e06a479f7a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train accuracy</td><td>▁▂▂▄▅▅▄▇█▇</td></tr><tr><td>train loss</td><td>█▆▇▅▄▄▄▂▁▂</td></tr><tr><td>valid accuracy</td><td>▁▃▂▅▅▅▃██▇</td></tr><tr><td>valid loss</td><td>█▅▆▄▃▄▅▂▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train accuracy</td><td>43.0</td></tr><tr><td>train loss</td><td>1.60942</td></tr><tr><td>valid accuracy</td><td>34.91746</td></tr><tr><td>valid loss</td><td>1.92522</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">laced-sweep-2</strong> at: <a href='https://wandb.ai/cs22m010/DL_Assign_2/runs/ynjnx1a3' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2/runs/ynjnx1a3</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20230411_002925-ynjnx1a3/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xvsp91vg with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_fn: ReLU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_augmentation: yes\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_org: double\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size_org: same\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_neuron_fc: 20\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.14.2 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.14.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230411_012511-xvsp91vg</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs22m010/DL_Assign_2/runs/xvsp91vg' target=\"_blank\">dandy-sweep-3</a></strong> to <a href='https://wandb.ai/cs22m010/DL_Assign_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs22m010/DL_Assign_2/sweeps/6589nodc' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2/sweeps/6589nodc</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs22m010/DL_Assign_2' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs22m010/DL_Assign_2/sweeps/6589nodc' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2/sweeps/6589nodc</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs22m010/DL_Assign_2/runs/xvsp91vg' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2/runs/xvsp91vg</a>"},"metadata":{}},{"name":"stdout","text":"epoch 0\nTraining Loss: 2.254030 \t Training Accuracy: 14.637500\nValidation Loss: 2.270104 \t Validation Accuracy: 13.356678\nepoch 1\nTraining Loss: 2.195614 \t Training Accuracy: 19.275000\nValidation Loss: 2.209666 \t Validation Accuracy: 18.609305\nepoch 2\nTraining Loss: 2.131111 \t Training Accuracy: 22.300000\nValidation Loss: 2.167874 \t Validation Accuracy: 20.110055\nepoch 3\nTraining Loss: 2.037576 \t Training Accuracy: 26.850000\nValidation Loss: 2.072492 \t Validation Accuracy: 25.912956\nepoch 4\nTraining Loss: 1.927898 \t Training Accuracy: 31.325000\nValidation Loss: 2.003951 \t Validation Accuracy: 28.964482\nepoch 5\nTraining Loss: 1.887357 \t Training Accuracy: 34.300000\nValidation Loss: 1.973727 \t Validation Accuracy: 30.665333\nepoch 6\nTraining Loss: 1.866363 \t Training Accuracy: 35.462500\nValidation Loss: 1.963081 \t Validation Accuracy: 31.315658\nepoch 7\nTraining Loss: 1.796041 \t Training Accuracy: 37.112500\nValidation Loss: 1.936520 \t Validation Accuracy: 32.466233\nepoch 8\nTraining Loss: 1.794085 \t Training Accuracy: 37.875000\nValidation Loss: 1.927895 \t Validation Accuracy: 33.366683\nepoch 9\nTraining Loss: 1.716773 \t Training Accuracy: 41.212500\nValidation Loss: 1.888224 \t Validation Accuracy: 33.416708\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26fe78eb35dd4823a3dd3f2f4df474cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train accuracy</td><td>▁▂▃▄▅▆▆▇▇█</td></tr><tr><td>train loss</td><td>█▇▆▅▄▃▃▂▂▁</td></tr><tr><td>valid accuracy</td><td>▁▃▃▅▆▇▇███</td></tr><tr><td>valid loss</td><td>█▇▆▄▃▃▂▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train accuracy</td><td>41.2125</td></tr><tr><td>train loss</td><td>1.71677</td></tr><tr><td>valid accuracy</td><td>33.41671</td></tr><tr><td>valid loss</td><td>1.88822</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">dandy-sweep-3</strong> at: <a href='https://wandb.ai/cs22m010/DL_Assign_2/runs/xvsp91vg' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2/runs/xvsp91vg</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20230411_012511-xvsp91vg/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: l6nt4gcp with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_fn: SiLU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_augmentation: no\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_org: double\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size_org: double\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_neuron_fc: 10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.14.2 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.14.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230411_022015-l6nt4gcp</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs22m010/DL_Assign_2/runs/l6nt4gcp' target=\"_blank\">lunar-sweep-4</a></strong> to <a href='https://wandb.ai/cs22m010/DL_Assign_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs22m010/DL_Assign_2/sweeps/6589nodc' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2/sweeps/6589nodc</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs22m010/DL_Assign_2' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs22m010/DL_Assign_2/sweeps/6589nodc' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2/sweeps/6589nodc</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs22m010/DL_Assign_2/runs/l6nt4gcp' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2/runs/l6nt4gcp</a>"},"metadata":{}},{"name":"stdout","text":"epoch 0\nTraining Loss: 2.303654 \t Training Accuracy: 11.087500\nValidation Loss: 2.301533 \t Validation Accuracy: 10.955478\nepoch 1\nTraining Loss: 2.286976 \t Training Accuracy: 14.437500\nValidation Loss: 2.289798 \t Validation Accuracy: 14.007004\nepoch 2\nTraining Loss: 2.305854 \t Training Accuracy: 10.250000\nValidation Loss: 2.306043 \t Validation Accuracy: 9.004502\nepoch 3\nTraining Loss: 2.303840 \t Training Accuracy: 10.250000\nValidation Loss: 2.304678 \t Validation Accuracy: 9.004502\nepoch 4\nTraining Loss: 2.303055 \t Training Accuracy: 10.250000\nValidation Loss: 2.304267 \t Validation Accuracy: 9.004502\nepoch 5\nTraining Loss: 2.302719 \t Training Accuracy: 10.250000\nValidation Loss: 2.303992 \t Validation Accuracy: 9.004502\nepoch 6\nTraining Loss: 2.302584 \t Training Accuracy: 10.250000\nValidation Loss: 2.304049 \t Validation Accuracy: 9.004502\nepoch 7\nTraining Loss: 2.302513 \t Training Accuracy: 10.250000\nValidation Loss: 2.304003 \t Validation Accuracy: 9.004502\nepoch 8\nTraining Loss: 2.302472 \t Training Accuracy: 10.250000\nValidation Loss: 2.304054 \t Validation Accuracy: 9.004502\nepoch 9\nTraining Loss: 2.302450 \t Training Accuracy: 10.250000\nValidation Loss: 2.303847 \t Validation Accuracy: 9.004502\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train accuracy</td><td>▂█▁▁▁▁▁▁▁▁</td></tr><tr><td>train loss</td><td>▇▁█▇▇▇▇▇▇▇</td></tr><tr><td>valid accuracy</td><td>▄█▁▁▁▁▁▁▁▁</td></tr><tr><td>valid loss</td><td>▆▁█▇▇▇▇▇▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train accuracy</td><td>10.25</td></tr><tr><td>train loss</td><td>2.30245</td></tr><tr><td>valid accuracy</td><td>9.0045</td></tr><tr><td>valid loss</td><td>2.30385</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">lunar-sweep-4</strong> at: <a href='https://wandb.ai/cs22m010/DL_Assign_2/runs/l6nt4gcp' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2/runs/l6nt4gcp</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20230411_022015-l6nt4gcp/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0me39qgk with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_fn: SiLU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_augmentation: yes\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_org: half\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size_org: same\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 96\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_neuron_fc: 10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.14.2 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.14.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230411_031513-0me39qgk</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs22m010/DL_Assign_2/runs/0me39qgk' target=\"_blank\">fiery-sweep-5</a></strong> to <a href='https://wandb.ai/cs22m010/DL_Assign_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs22m010/DL_Assign_2/sweeps/6589nodc' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2/sweeps/6589nodc</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs22m010/DL_Assign_2' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs22m010/DL_Assign_2/sweeps/6589nodc' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2/sweeps/6589nodc</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs22m010/DL_Assign_2/runs/0me39qgk' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2/runs/0me39qgk</a>"},"metadata":{}},{"name":"stdout","text":"epoch 0\nTraining Loss: 2.117808 \t Training Accuracy: 23.525000\nValidation Loss: 2.139379 \t Validation Accuracy: 20.560280\nepoch 1\nTraining Loss: 2.059130 \t Training Accuracy: 25.612500\nValidation Loss: 2.101816 \t Validation Accuracy: 23.361681\nepoch 2\nTraining Loss: 1.950260 \t Training Accuracy: 30.462500\nValidation Loss: 2.007750 \t Validation Accuracy: 27.013507\nepoch 3\nTraining Loss: 1.909456 \t Training Accuracy: 32.375000\nValidation Loss: 1.978387 \t Validation Accuracy: 28.164082\nepoch 4\nTraining Loss: 1.822124 \t Training Accuracy: 36.837500\nValidation Loss: 1.926461 \t Validation Accuracy: 31.765883\nepoch 5\nTraining Loss: 1.839938 \t Training Accuracy: 34.887500\nValidation Loss: 1.946394 \t Validation Accuracy: 29.414707\nepoch 6\nTraining Loss: 1.829859 \t Training Accuracy: 35.750000\nValidation Loss: 1.948643 \t Validation Accuracy: 30.315158\nepoch 7\nTraining Loss: 1.819116 \t Training Accuracy: 37.100000\nValidation Loss: 1.903285 \t Validation Accuracy: 32.216108\nepoch 8\nTraining Loss: 1.837777 \t Training Accuracy: 35.337500\nValidation Loss: 1.956070 \t Validation Accuracy: 30.165083\nepoch 9\nTraining Loss: 1.719946 \t Training Accuracy: 39.787500\nValidation Loss: 1.854097 \t Validation Accuracy: 34.017009\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f28ef3b31ea240439881eca1247c3a84"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train accuracy</td><td>▁▂▄▅▇▆▆▇▆█</td></tr><tr><td>train loss</td><td>█▇▅▄▃▃▃▃▃▁</td></tr><tr><td>valid accuracy</td><td>▁▂▄▅▇▆▆▇▆█</td></tr><tr><td>valid loss</td><td>█▇▅▄▃▃▃▂▄▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train accuracy</td><td>39.7875</td></tr><tr><td>train loss</td><td>1.71995</td></tr><tr><td>valid accuracy</td><td>34.01701</td></tr><tr><td>valid loss</td><td>1.8541</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">fiery-sweep-5</strong> at: <a href='https://wandb.ai/cs22m010/DL_Assign_2/runs/0me39qgk' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2/runs/0me39qgk</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20230411_031513-0me39qgk/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1knpg8li with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_fn: ReLU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_augmentation: yes\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_org: double\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size_org: same\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 96\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_neuron_fc: 20\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.14.2 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.14.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230411_041008-1knpg8li</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs22m010/DL_Assign_2/runs/1knpg8li' target=\"_blank\">vital-sweep-6</a></strong> to <a href='https://wandb.ai/cs22m010/DL_Assign_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs22m010/DL_Assign_2/sweeps/6589nodc' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2/sweeps/6589nodc</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs22m010/DL_Assign_2' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs22m010/DL_Assign_2/sweeps/6589nodc' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2/sweeps/6589nodc</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs22m010/DL_Assign_2/runs/1knpg8li' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2/runs/1knpg8li</a>"},"metadata":{}},{"name":"stdout","text":"epoch 0\nTraining Loss: 2.308240 \t Training Accuracy: 15.975000\nValidation Loss: 2.342752 \t Validation Accuracy: 16.408204\nepoch 1\nTraining Loss: 2.139722 \t Training Accuracy: 23.212500\nValidation Loss: 2.166004 \t Validation Accuracy: 22.211106\nepoch 2\nTraining Loss: 2.059922 \t Training Accuracy: 27.587500\nValidation Loss: 2.106660 \t Validation Accuracy: 26.613307\nepoch 3\nTraining Loss: 2.053868 \t Training Accuracy: 27.262500\nValidation Loss: 2.134398 \t Validation Accuracy: 24.062031\nepoch 4\nTraining Loss: 2.028343 \t Training Accuracy: 27.112500\nValidation Loss: 2.086069 \t Validation Accuracy: 26.263132\nepoch 5\nTraining Loss: 1.813044 \t Training Accuracy: 36.737500\nValidation Loss: 1.921970 \t Validation Accuracy: 32.866433\nepoch 6\nTraining Loss: 1.881234 \t Training Accuracy: 32.637500\nValidation Loss: 2.000839 \t Validation Accuracy: 30.165083\nepoch 7\nTraining Loss: 1.746235 \t Training Accuracy: 39.187500\nValidation Loss: 1.902032 \t Validation Accuracy: 35.217609\nepoch 8\nTraining Loss: 1.732325 \t Training Accuracy: 39.862500\nValidation Loss: 1.910367 \t Validation Accuracy: 35.017509\nepoch 9\nTraining Loss: 1.718809 \t Training Accuracy: 39.637500\nValidation Loss: 1.948249 \t Validation Accuracy: 32.666333\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28555a0a96ae42fbaa43c6ef158596d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train accuracy</td><td>▁▃▄▄▄▇▆███</td></tr><tr><td>train loss</td><td>█▆▅▅▅▂▃▁▁▁</td></tr><tr><td>valid accuracy</td><td>▁▃▅▄▅▇▆██▇</td></tr><tr><td>valid loss</td><td>█▅▄▅▄▁▃▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train accuracy</td><td>39.6375</td></tr><tr><td>train loss</td><td>1.71881</td></tr><tr><td>valid accuracy</td><td>32.66633</td></tr><tr><td>valid loss</td><td>1.94825</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">vital-sweep-6</strong> at: <a href='https://wandb.ai/cs22m010/DL_Assign_2/runs/1knpg8li' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2/runs/1knpg8li</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20230411_041008-1knpg8li/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: fx5semsq with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_fn: Mish\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_augmentation: yes\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_org: half\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 7\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size_org: same\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 96\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_neuron_fc: 10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.14.2 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.14.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230411_050652-fx5semsq</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs22m010/DL_Assign_2/runs/fx5semsq' target=\"_blank\">wandering-sweep-7</a></strong> to <a href='https://wandb.ai/cs22m010/DL_Assign_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs22m010/DL_Assign_2/sweeps/6589nodc' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2/sweeps/6589nodc</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs22m010/DL_Assign_2' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs22m010/DL_Assign_2/sweeps/6589nodc' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2/sweeps/6589nodc</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs22m010/DL_Assign_2/runs/fx5semsq' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2/runs/fx5semsq</a>"},"metadata":{}},{"name":"stdout","text":"epoch 0\nTraining Loss: 2.304503 \t Training Accuracy: 10.112500\nValidation Loss: 2.297699 \t Validation Accuracy: 9.354677\nepoch 1\nTraining Loss: 2.312073 \t Training Accuracy: 9.925000\nValidation Loss: 2.306317 \t Validation Accuracy: 9.804902\nepoch 2\nTraining Loss: 2.306448 \t Training Accuracy: 10.012500\nValidation Loss: 2.303201 \t Validation Accuracy: 9.954977\nepoch 3\nTraining Loss: 2.304156 \t Training Accuracy: 10.012500\nValidation Loss: 2.302570 \t Validation Accuracy: 9.954977\nepoch 4\nTraining Loss: 2.303100 \t Training Accuracy: 10.012500\nValidation Loss: 2.302509 \t Validation Accuracy: 9.954977\nepoch 5\nTraining Loss: 2.302696 \t Training Accuracy: 10.300000\nValidation Loss: 2.302861 \t Validation Accuracy: 8.804402\nepoch 6\nTraining Loss: 2.302536 \t Training Accuracy: 10.300000\nValidation Loss: 2.303083 \t Validation Accuracy: 8.804402\nepoch 7\nTraining Loss: 2.302473 \t Training Accuracy: 10.300000\nValidation Loss: 2.303446 \t Validation Accuracy: 8.804402\nepoch 8\nTraining Loss: 2.302460 \t Training Accuracy: 10.300000\nValidation Loss: 2.303673 \t Validation Accuracy: 8.804402\nepoch 9\nTraining Loss: 2.302448 \t Training Accuracy: 10.300000\nValidation Loss: 2.303721 \t Validation Accuracy: 8.804402\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train accuracy</td><td>▅▁▃▃▃█████</td></tr><tr><td>train loss</td><td>▂█▄▂▁▁▁▁▁▁</td></tr><tr><td>valid accuracy</td><td>▄▇███▁▁▁▁▁</td></tr><tr><td>valid loss</td><td>▁█▅▅▅▅▅▆▆▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train accuracy</td><td>10.3</td></tr><tr><td>train loss</td><td>2.30245</td></tr><tr><td>valid accuracy</td><td>8.8044</td></tr><tr><td>valid loss</td><td>2.30372</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">wandering-sweep-7</strong> at: <a href='https://wandb.ai/cs22m010/DL_Assign_2/runs/fx5semsq' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2/runs/fx5semsq</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20230411_050652-fx5semsq/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: dvb6q44h with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_fn: Mish\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_augmentation: no\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_org: double\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 7\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size_org: same\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_neuron_fc: 20\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.14.2 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.14.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230411_060236-dvb6q44h</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs22m010/DL_Assign_2/runs/dvb6q44h' target=\"_blank\">helpful-sweep-8</a></strong> to <a href='https://wandb.ai/cs22m010/DL_Assign_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs22m010/DL_Assign_2/sweeps/6589nodc' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2/sweeps/6589nodc</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs22m010/DL_Assign_2' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs22m010/DL_Assign_2/sweeps/6589nodc' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2/sweeps/6589nodc</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs22m010/DL_Assign_2/runs/dvb6q44h' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2/runs/dvb6q44h</a>"},"metadata":{}},{"name":"stdout","text":"epoch 0\nTraining Loss: 2.173055 \t Training Accuracy: 21.400000\nValidation Loss: 2.214001 \t Validation Accuracy: 19.709855\nepoch 1\nTraining Loss: 2.052245 \t Training Accuracy: 27.125000\nValidation Loss: 2.119322 \t Validation Accuracy: 24.712356\nepoch 2\nTraining Loss: 2.053280 \t Training Accuracy: 27.737500\nValidation Loss: 2.153294 \t Validation Accuracy: 23.211606\nepoch 3\nTraining Loss: 1.935625 \t Training Accuracy: 31.575000\nValidation Loss: 2.046730 \t Validation Accuracy: 27.263632\nepoch 4\nTraining Loss: 1.843801 \t Training Accuracy: 35.000000\nValidation Loss: 1.976279 \t Validation Accuracy: 28.764382\nepoch 5\nTraining Loss: 1.855812 \t Training Accuracy: 34.475000\nValidation Loss: 1.990086 \t Validation Accuracy: 27.763882\nepoch 6\nTraining Loss: 1.747184 \t Training Accuracy: 38.762500\nValidation Loss: 1.936390 \t Validation Accuracy: 32.316158\nepoch 7\nTraining Loss: 1.869956 \t Training Accuracy: 34.575000\nValidation Loss: 2.088754 \t Validation Accuracy: 25.662831\nepoch 8\nTraining Loss: 1.740655 \t Training Accuracy: 39.000000\nValidation Loss: 1.983264 \t Validation Accuracy: 31.515758\nepoch 9\nTraining Loss: 1.546415 \t Training Accuracy: 47.000000\nValidation Loss: 1.872213 \t Validation Accuracy: 34.217109\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9dd91f989efa4b478bfd72bb2f9aa432"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train accuracy</td><td>▁▃▃▄▅▅▆▅▆█</td></tr><tr><td>train loss</td><td>█▇▇▅▄▄▃▅▃▁</td></tr><tr><td>valid accuracy</td><td>▁▃▃▅▅▅▇▄▇█</td></tr><tr><td>valid loss</td><td>█▆▇▅▃▃▂▅▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train accuracy</td><td>47.0</td></tr><tr><td>train loss</td><td>1.54642</td></tr><tr><td>valid accuracy</td><td>34.21711</td></tr><tr><td>valid loss</td><td>1.87221</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">helpful-sweep-8</strong> at: <a href='https://wandb.ai/cs22m010/DL_Assign_2/runs/dvb6q44h' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2/runs/dvb6q44h</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20230411_060236-dvb6q44h/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gkdgrbpo with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_fn: GELU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_augmentation: yes\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_org: same\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 7\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size_org: same\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 96\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_neuron_fc: 10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.14.2 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.14.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230411_065915-gkdgrbpo</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs22m010/DL_Assign_2/runs/gkdgrbpo' target=\"_blank\">grateful-sweep-9</a></strong> to <a href='https://wandb.ai/cs22m010/DL_Assign_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs22m010/DL_Assign_2/sweeps/6589nodc' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2/sweeps/6589nodc</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs22m010/DL_Assign_2' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs22m010/DL_Assign_2/sweeps/6589nodc' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2/sweeps/6589nodc</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs22m010/DL_Assign_2/runs/gkdgrbpo' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2/runs/gkdgrbpo</a>"},"metadata":{}},{"name":"stdout","text":"epoch 0\nTraining Loss: 2.306835 \t Training Accuracy: 10.087500\nValidation Loss: 2.310891 \t Validation Accuracy: 9.854927\nepoch 1\nTraining Loss: 2.301169 \t Training Accuracy: 11.500000\nValidation Loss: 2.304988 \t Validation Accuracy: 11.655828\nepoch 2\nTraining Loss: 2.293572 \t Training Accuracy: 10.662500\nValidation Loss: 2.297312 \t Validation Accuracy: 9.604802\nepoch 3\nTraining Loss: 2.306994 \t Training Accuracy: 10.037500\nValidation Loss: 2.308803 \t Validation Accuracy: 9.854927\nepoch 4\nTraining Loss: 2.303920 \t Training Accuracy: 10.037500\nValidation Loss: 2.305633 \t Validation Accuracy: 9.854927\nepoch 5\nTraining Loss: 2.302911 \t Training Accuracy: 10.037500\nValidation Loss: 2.304557 \t Validation Accuracy: 9.854927\nepoch 6\nTraining Loss: 2.302612 \t Training Accuracy: 10.262500\nValidation Loss: 2.303932 \t Validation Accuracy: 8.904452\nepoch 7\nTraining Loss: 2.302512 \t Training Accuracy: 10.262500\nValidation Loss: 2.303741 \t Validation Accuracy: 8.904452\nepoch 8\nTraining Loss: 2.302484 \t Training Accuracy: 10.262500\nValidation Loss: 2.303615 \t Validation Accuracy: 8.904452\nepoch 9\nTraining Loss: 2.302475 \t Training Accuracy: 10.262500\nValidation Loss: 2.303504 \t Validation Accuracy: 8.904452\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.028 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.038260…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"231457fed37f4ed3b2cac341be765f7a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train accuracy</td><td>▁█▄▁▁▁▂▂▂▂</td></tr><tr><td>train loss</td><td>█▅▁█▆▆▆▆▆▆</td></tr><tr><td>valid accuracy</td><td>▃█▃▃▃▃▁▁▁▁</td></tr><tr><td>valid loss</td><td>█▅▁▇▅▅▄▄▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train accuracy</td><td>10.2625</td></tr><tr><td>train loss</td><td>2.30248</td></tr><tr><td>valid accuracy</td><td>8.90445</td></tr><tr><td>valid loss</td><td>2.3035</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">grateful-sweep-9</strong> at: <a href='https://wandb.ai/cs22m010/DL_Assign_2/runs/gkdgrbpo' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2/runs/gkdgrbpo</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20230411_065915-gkdgrbpo/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: tifheazl with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_fn: SiLU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_augmentation: yes\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_org: same\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size_org: double\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_neuron_fc: 20\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.14.2 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.14.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230411_075457-tifheazl</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs22m010/DL_Assign_2/runs/tifheazl' target=\"_blank\">fiery-sweep-10</a></strong> to <a href='https://wandb.ai/cs22m010/DL_Assign_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs22m010/DL_Assign_2/sweeps/6589nodc' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2/sweeps/6589nodc</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs22m010/DL_Assign_2' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs22m010/DL_Assign_2/sweeps/6589nodc' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2/sweeps/6589nodc</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs22m010/DL_Assign_2/runs/tifheazl' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2/runs/tifheazl</a>"},"metadata":{}},{"name":"stdout","text":"epoch 0\nTraining Loss: 2.121746 \t Training Accuracy: 22.925000\nValidation Loss: 2.126791 \t Validation Accuracy: 22.461231\nepoch 1\nTraining Loss: 2.004401 \t Training Accuracy: 29.612500\nValidation Loss: 2.038242 \t Validation Accuracy: 28.564282\nepoch 2\nTraining Loss: 1.888073 \t Training Accuracy: 33.350000\nValidation Loss: 1.961412 \t Validation Accuracy: 30.515258\nepoch 3\nTraining Loss: 1.887966 \t Training Accuracy: 32.987500\nValidation Loss: 1.977747 \t Validation Accuracy: 28.614307\nepoch 4\nTraining Loss: 2.757155 \t Training Accuracy: 20.637500\nValidation Loss: 2.802505 \t Validation Accuracy: 21.210605\nepoch 5\nTraining Loss: 1.803335 \t Training Accuracy: 35.550000\nValidation Loss: 1.906857 \t Validation Accuracy: 32.966483\nepoch 6\nTraining Loss: 1.703808 \t Training Accuracy: 39.837500\nValidation Loss: 1.814398 \t Validation Accuracy: 34.867434\nepoch 7\nTraining Loss: 1.700913 \t Training Accuracy: 40.737500\nValidation Loss: 1.820397 \t Validation Accuracy: 34.117059\nepoch 8\nTraining Loss: 1.739283 \t Training Accuracy: 39.037500\nValidation Loss: 1.902510 \t Validation Accuracy: 31.915958\nepoch 9\nTraining Loss: 1.650957 \t Training Accuracy: 42.400000\nValidation Loss: 1.852971 \t Validation Accuracy: 35.717859\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train accuracy</td><td>▂▄▅▅▁▆▇▇▇█</td></tr><tr><td>train loss</td><td>▄▃▃▂█▂▁▁▂▁</td></tr><tr><td>valid accuracy</td><td>▂▅▅▅▁▇█▇▆█</td></tr><tr><td>valid loss</td><td>▃▃▂▂█▂▁▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train accuracy</td><td>42.4</td></tr><tr><td>train loss</td><td>1.65096</td></tr><tr><td>valid accuracy</td><td>35.71786</td></tr><tr><td>valid loss</td><td>1.85297</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">fiery-sweep-10</strong> at: <a href='https://wandb.ai/cs22m010/DL_Assign_2/runs/tifheazl' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2/runs/tifheazl</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20230411_075457-tifheazl/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: s0s75192 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_fn: GELU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_augmentation: yes\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_org: same\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size_org: same\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_neuron_fc: 20\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.14.2 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.14.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230411_084921-s0s75192</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs22m010/DL_Assign_2/runs/s0s75192' target=\"_blank\">hopeful-sweep-11</a></strong> to <a href='https://wandb.ai/cs22m010/DL_Assign_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs22m010/DL_Assign_2/sweeps/6589nodc' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2/sweeps/6589nodc</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs22m010/DL_Assign_2' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs22m010/DL_Assign_2/sweeps/6589nodc' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2/sweeps/6589nodc</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs22m010/DL_Assign_2/runs/s0s75192' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2/runs/s0s75192</a>"},"metadata":{}},{"name":"stdout","text":"epoch 0\nTraining Loss: 2.187184 \t Training Accuracy: 20.362500\nValidation Loss: 2.174560 \t Validation Accuracy: 19.459730\nepoch 1\nTraining Loss: 2.082457 \t Training Accuracy: 24.362500\nValidation Loss: 2.066376 \t Validation Accuracy: 24.912456\nepoch 2\nTraining Loss: 1.998758 \t Training Accuracy: 28.900000\nValidation Loss: 1.981743 \t Validation Accuracy: 29.764882\nepoch 3\nTraining Loss: 2.016927 \t Training Accuracy: 27.962500\nValidation Loss: 2.006862 \t Validation Accuracy: 28.264132\nepoch 4\nTraining Loss: 1.916641 \t Training Accuracy: 31.775000\nValidation Loss: 1.913226 \t Validation Accuracy: 32.566283\nepoch 5\nTraining Loss: 1.878971 \t Training Accuracy: 33.962500\nValidation Loss: 1.888255 \t Validation Accuracy: 33.816908\nepoch 6\nTraining Loss: 1.850146 \t Training Accuracy: 35.337500\nValidation Loss: 1.876087 \t Validation Accuracy: 34.167084\nepoch 7\nTraining Loss: 1.818314 \t Training Accuracy: 36.887500\nValidation Loss: 1.882712 \t Validation Accuracy: 35.217609\nepoch 8\nTraining Loss: 1.767982 \t Training Accuracy: 37.312500\nValidation Loss: 1.847299 \t Validation Accuracy: 34.017009\nepoch 9\nTraining Loss: 1.688353 \t Training Accuracy: 41.587500\nValidation Loss: 1.807644 \t Validation Accuracy: 36.418209\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"132e197f14cb4ff6b0c709770123372c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train accuracy</td><td>▁▂▄▄▅▅▆▆▇█</td></tr><tr><td>train loss</td><td>█▇▅▆▄▄▃▃▂▁</td></tr><tr><td>valid accuracy</td><td>▁▃▅▅▆▇▇█▇█</td></tr><tr><td>valid loss</td><td>█▆▄▅▃▃▂▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train accuracy</td><td>41.5875</td></tr><tr><td>train loss</td><td>1.68835</td></tr><tr><td>valid accuracy</td><td>36.41821</td></tr><tr><td>valid loss</td><td>1.80764</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">hopeful-sweep-11</strong> at: <a href='https://wandb.ai/cs22m010/DL_Assign_2/runs/s0s75192' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2/runs/s0s75192</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20230411_084921-s0s75192/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: d8tw1t0b with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_fn: SiLU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_augmentation: no\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_org: double\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size_org: same\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_neuron_fc: 10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.14.2 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.14.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230411_094312-d8tw1t0b</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs22m010/DL_Assign_2/runs/d8tw1t0b' target=\"_blank\">clear-sweep-12</a></strong> to <a href='https://wandb.ai/cs22m010/DL_Assign_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs22m010/DL_Assign_2/sweeps/6589nodc' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2/sweeps/6589nodc</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs22m010/DL_Assign_2' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs22m010/DL_Assign_2/sweeps/6589nodc' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2/sweeps/6589nodc</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs22m010/DL_Assign_2/runs/d8tw1t0b' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2/runs/d8tw1t0b</a>"},"metadata":{}},{"name":"stdout","text":"epoch 0\nTraining Loss: 2.145982 \t Training Accuracy: 22.375000\nValidation Loss: 2.184001 \t Validation Accuracy: 21.710855\nepoch 1\nTraining Loss: 2.063264 \t Training Accuracy: 26.100000\nValidation Loss: 2.145625 \t Validation Accuracy: 22.711356\nepoch 2\nTraining Loss: 1.922119 \t Training Accuracy: 31.137500\nValidation Loss: 2.021696 \t Validation Accuracy: 29.014507\nepoch 3\nTraining Loss: 1.858137 \t Training Accuracy: 34.800000\nValidation Loss: 2.000149 \t Validation Accuracy: 29.264632\nepoch 4\nTraining Loss: 1.901079 \t Training Accuracy: 33.862500\nValidation Loss: 2.019307 \t Validation Accuracy: 28.464232\nepoch 5\nTraining Loss: 1.682510 \t Training Accuracy: 41.962500\nValidation Loss: 1.896844 \t Validation Accuracy: 33.416708\nepoch 6\nTraining Loss: 1.803250 \t Training Accuracy: 36.325000\nValidation Loss: 1.991815 \t Validation Accuracy: 29.664832\nepoch 7\nTraining Loss: 1.700917 \t Training Accuracy: 40.100000\nValidation Loss: 1.940706 \t Validation Accuracy: 31.465733\nepoch 8\nTraining Loss: 1.758704 \t Training Accuracy: 38.800000\nValidation Loss: 2.028845 \t Validation Accuracy: 30.565283\nepoch 9\nTraining Loss: 1.713926 \t Training Accuracy: 39.000000\nValidation Loss: 1.967752 \t Validation Accuracy: 31.115558\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.026 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.041013…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51f8b81d519f4f748ad238e8225e96fa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train accuracy</td><td>▁▂▄▅▅█▆▇▇▇</td></tr><tr><td>train loss</td><td>█▇▅▄▄▁▃▁▂▁</td></tr><tr><td>valid accuracy</td><td>▁▂▅▆▅█▆▇▆▇</td></tr><tr><td>valid loss</td><td>█▇▄▄▄▁▃▂▄▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train accuracy</td><td>39.0</td></tr><tr><td>train loss</td><td>1.71393</td></tr><tr><td>valid accuracy</td><td>31.11556</td></tr><tr><td>valid loss</td><td>1.96775</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">clear-sweep-12</strong> at: <a href='https://wandb.ai/cs22m010/DL_Assign_2/runs/d8tw1t0b' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2/runs/d8tw1t0b</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20230411_094312-d8tw1t0b/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: lspxqlwl with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_fn: ReLU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_augmentation: yes\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_org: same\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size_org: same\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_neuron_fc: 20\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.14.2 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.14.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230411_103751-lspxqlwl</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs22m010/DL_Assign_2/runs/lspxqlwl' target=\"_blank\">eternal-sweep-13</a></strong> to <a href='https://wandb.ai/cs22m010/DL_Assign_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs22m010/DL_Assign_2/sweeps/6589nodc' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2/sweeps/6589nodc</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs22m010/DL_Assign_2' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs22m010/DL_Assign_2/sweeps/6589nodc' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2/sweeps/6589nodc</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs22m010/DL_Assign_2/runs/lspxqlwl' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2/runs/lspxqlwl</a>"},"metadata":{}},{"name":"stdout","text":"epoch 0\nTraining Loss: 2.132591 \t Training Accuracy: 23.262500\nValidation Loss: 2.129553 \t Validation Accuracy: 23.661831\nepoch 1\nTraining Loss: 2.126289 \t Training Accuracy: 24.262500\nValidation Loss: 2.138192 \t Validation Accuracy: 23.611806\nepoch 2\nTraining Loss: 2.011214 \t Training Accuracy: 29.962500\nValidation Loss: 2.019235 \t Validation Accuracy: 29.964982\nepoch 3\nTraining Loss: 2.009345 \t Training Accuracy: 28.575000\nValidation Loss: 2.018676 \t Validation Accuracy: 28.764382\nepoch 4\nTraining Loss: 1.993118 \t Training Accuracy: 29.800000\nValidation Loss: 2.006251 \t Validation Accuracy: 29.814907\nepoch 5\nTraining Loss: 1.891638 \t Training Accuracy: 35.362500\nValidation Loss: 1.931354 \t Validation Accuracy: 32.966483\nepoch 6\nTraining Loss: 1.868461 \t Training Accuracy: 34.800000\nValidation Loss: 1.923097 \t Validation Accuracy: 32.816408\nepoch 7\nTraining Loss: 1.908411 \t Training Accuracy: 31.025000\nValidation Loss: 1.937110 \t Validation Accuracy: 31.015508\nepoch 8\nTraining Loss: 1.844065 \t Training Accuracy: 34.975000\nValidation Loss: 1.900874 \t Validation Accuracy: 31.665833\nepoch 9\nTraining Loss: 1.971384 \t Training Accuracy: 29.137500\nValidation Loss: 2.000623 \t Validation Accuracy: 29.414707\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train accuracy</td><td>▁▂▅▄▅██▅█▄</td></tr><tr><td>train loss</td><td>██▅▅▅▂▂▃▁▄</td></tr><tr><td>valid accuracy</td><td>▁▁▆▅▆██▇▇▅</td></tr><tr><td>valid loss</td><td>██▄▄▄▂▂▂▁▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train accuracy</td><td>29.1375</td></tr><tr><td>train loss</td><td>1.97138</td></tr><tr><td>valid accuracy</td><td>29.41471</td></tr><tr><td>valid loss</td><td>2.00062</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">eternal-sweep-13</strong> at: <a href='https://wandb.ai/cs22m010/DL_Assign_2/runs/lspxqlwl' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2/runs/lspxqlwl</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20230411_103751-lspxqlwl/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1e9rlzsu with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_fn: SiLU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_augmentation: yes\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_org: half\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size_org: double\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_neuron_fc: 20\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.14.2 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.14.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230411_113116-1e9rlzsu</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs22m010/DL_Assign_2/runs/1e9rlzsu' target=\"_blank\">quiet-sweep-14</a></strong> to <a href='https://wandb.ai/cs22m010/DL_Assign_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs22m010/DL_Assign_2/sweeps/6589nodc' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2/sweeps/6589nodc</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs22m010/DL_Assign_2' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs22m010/DL_Assign_2/sweeps/6589nodc' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2/sweeps/6589nodc</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs22m010/DL_Assign_2/runs/1e9rlzsu' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2/runs/1e9rlzsu</a>"},"metadata":{}}]},{"cell_type":"code","source":"# import torch\n# import matplotlib.pyplot as plt\n\n# # Load an image into a PyTorch tensor\n# for i in range(1):\n#     img=train_loader[i][0].numpy().transpose((1,2,0))\n    \n# # img_tensor = torch.randn(3, 256, 256)\n\n# # # Convert the tensor to a NumPy array\n# # img = img_tensor.numpy().transpose((1, 2, 0))\n\n# plt.imshow(grid.permute(1, 2, 0))\n\n# # Display the image\n#     plt.imshow(img)\n#     plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-09T18:07:24.931478Z","iopub.execute_input":"2023-04-09T18:07:24.932180Z","iopub.status.idle":"2023-04-09T18:07:24.937175Z","shell.execute_reply.started":"2023-04-09T18:07:24.932144Z","shell.execute_reply":"2023-04-09T18:07:24.935623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import os\n# from PIL import Image\n# import numpy as np\n# #import tensorflow as tf\n# import torchvision\n# import torchvision.transforms as transforms\n# from torch.utils.data import DataLoader\n# from torch.utils.data import random_split\n# import torch\n# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# data_dir = '/kaggle/input/inaturalist12k/Data/inaturalist_12K'\n# transform = transforms.Compose([transforms.Resize((256,256)),transforms.ToTensor()])\n\n# train_dataset=torchvision.datasets.ImageFolder(root=data_dir+'/train',transform=transform)\n# test_dataset=torchvision.datasets.ImageFolder(root=data_dir+'/val',transform=transform)\n\n# val_size = int(len(train_dataset) * 0.5)\n# train_size = len(train_dataset) - val_size\n\n# train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n\n# train_loader=DataLoader(train_dataset,batch_size=64,shuffle=True)\n# val_loader=DataLoader(val_dataset,batch_size=64,shuffle=False)\n# test_loader=DataLoader(test_dataset,batch_size=64,shuffle=False)\n\n\n\n\n\n\n# import torch.nn as nn\n# import torch.optim as optim\n\n# # Define the CNN model architecture\n# class CNN(nn.Module):\n#     def __init__(self, num_filters, filter_size, activation_fn, filter_org, batch_norm, dropout):\n#         super(CNN, self).__init__()\n#         layers = []\n#         in_channels = 3\n#         for i, f in enumerate(filter_org):\n#             out_channels = num_filters * f\n#             layers.append(nn.Conv2d(in_channels, out_channels, filter_size, padding=1))\n#             if batch_norm:\n#                 layers.append(nn.BatchNorm2d(out_channels))\n#             layers.append(activation_fn())\n#             layers.append(nn.MaxPool2d(2))\n#             if dropout > 0:\n#                 layers.append(nn.Dropout(dropout))\n#             in_channels = out_channels\n#         self.cnn = nn.Sequential(*layers)\n#         self.fc = nn.Linear(out_channels * 32 * 32, 10)\n\n#     def forward(self, x):\n#         x = self.cnn(x)\n#         x = x.view(x.size(0), -1)\n#         x = self.fc(x)\n#         return x\n\n# # Define the model hyperparameters\n# num_filters = 32\n# filter_size = 3\n# activation_fn = nn.ReLU\n# filter_org = [1,2,2]\n# batch_norm = True\n# dropout = 0.3\n\n# # Initialize the model\n# model = CNN(num_filters, filter_size, activation_fn, filter_org, batch_norm, dropout).to(device)\n\n# # Define the loss function and optimizer\n# criterion = nn.CrossEntropyLoss()\n# optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# # Train the model\n# num_epochs = 5\n# for epoch in range(num_epochs):\n#     model.train()\n#     train_loss = 0.0\n#     correct = 0\n#     total = 0\n#     for batch_idx, (data, target) in enumerate(train_loader):\n#         data, target = data.to(device), target.to(device)# Move data and target to the device\n#         optimizer.zero_grad()\n#         output = model(data)\n#         loss = criterion(output, target)\n#         loss.backward()\n#         optimizer.step()\n#         train_loss += loss.item()\n#         _, predicted = torch.max(output.data, 1)\n#         total += target.size(0)\n#         correct += (predicted == target).sum().item()\n        \n#     # Calculate training metrics\n#     train_loss /= len(train_loader)\n#     train_accuracy = 100 * correct / total\n    \n#     # Set model to evaluation mode\n#     model.eval()\n#     val_loss = 0.0\n#     correct = 0\n#     total = 0\n#     with torch.no_grad():\n#         for batch_idx, (data, target) in enumerate(val_loader):\n#             data, target = data.to(device), target.to(device)# Move data and target to the device\n#             output = model(data)\n#             loss = criterion(output, target)\n#             val_loss += loss.item()\n#             _, predicted = torch.max(output.data, 1)\n#             total += target.size(0)\n#             correct += (predicted == target).sum().item()\n            \n#     # Calculate validation metrics\n#     val_loss /= len(val_loader)\n#     val_accuracy = 100 * correct / total\n    \n#     # Print metrics for current epoch\n#     #print('Epoch: {} \\t Training Loss: {:.6f}\n#     print(\"epoch\",epoch)\n          \n#     print('Training Loss: {:.6f} \\t Training Accuracy: {:.6f}'.format(train_loss, train_accuracy))\n#     print('Validation Loss: {:.6f} \\t Validation Accuracy: {:.6f}'.format(val_loss, val_accuracy))\n\n\n\n\n\n    \n    \n    \n    \n    \n# #     train_loss = 0.0\n# #     for batch_idx, (data, target) in enumerate(train_loader): \n# #         data, target = data.to(device), target.to(device)# Move data and target to the device\n# #         optimizer.zero_grad()\n# #         output = model(data)\n# #         loss = criterion(output, target)\n# #         loss.backward()\n# #         optimizer.step()\n# #         train_loss += loss.item()\n\n# #     print('Epoch: {} \\t Training Loss: {:.6f}'.format(epoch+1, train_loss/len(train_loader)))\n    \n# #     # Evaluate the model on train_loader\n# #     model.eval()\n# #     train_correct = 0\n# #     train_total = 0\n# #     train_loss = 0.0\n# #     with torch.no_grad():\n# #         for data, target in train_loader:\n# #             output = model(data)\n# #             loss = criterion(output, target)\n# #             train_loss += loss.item()\n# #             _, predicted = torch.max(output.data, 1)\n# #             train_total += target.size(0)\n# #             train_correct += (predicted == target).sum().item()\n\n# #     train_accuracy = train_correct/train_total\n# #     train_loss /= len(train_loader)\n\n# #     # Evaluate the model on val_loader\n# #     model.eval()\n# #     val_correct = 0\n# #     val_total = 0\n# #     val_loss = 0.0\n# #     with torch.no_grad():\n# #         for data, target in val_loader:\n# #             output = model(data)\n# #             loss = criterion(output, target)\n# #             val_loss += loss.item()\n# #             _, predicted = torch.max(output.data, 1)\n# #             val_total += target.size(0)\n# #             val_correct += (predicted == target).sum().item()\n\n# #     val_accuracy = val_correct/val_total\n# #     val_loss /= len(val_loader)\n\n# #     print('Training Loss: {:.6f} \\t Training Accuracy: {:.6f}'.format(train_loss, train_accuracy))\n# #     print('Validation Loss: {:.6f} \\t Validation Accuracy: {:.6f}'.format(val_loss, val_accuracy))\n\n","metadata":{"execution":{"iopub.status.busy":"2023-04-08T15:37:56.476412Z","iopub.execute_input":"2023-04-08T15:37:56.476829Z","iopub.status.idle":"2023-04-08T15:37:58.123794Z","shell.execute_reply.started":"2023-04-08T15:37:56.476794Z","shell.execute_reply":"2023-04-08T15:37:58.122340Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
