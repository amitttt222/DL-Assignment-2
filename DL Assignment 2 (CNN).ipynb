{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import os\n# from PIL import Image\n# import numpy as np\n\n# def load_data(data_dir):\n#     images = []\n#     labels = []\n#     classes = os.listdir(data_dir)\n#     for cls in classes:\n#         cls_path = os.path.join(data_dir, cls)\n#         if os.path.isdir(cls_path):\n#             cls_images = os.listdir(cls_path)\n#             for img_name in cls_images:\n#                 img_path = os.path.join(cls_path, img_name)\n#                 img = Image.open(img_path).resize((224, 224))\n#                 img = np.array(img) / 255.0\n#                 images.append(img)\n#                 labels.append(cls)\n#     return np.array(images), np.array(labels)\n\n\n# data_dir = '/kaggle/input/inaturalist12k/Data/inaturalist_12K'\n\n# train_dir = os.path.join(data_dir, 'train')\n# X_train, y_train = load_data(train_dir)\n\n# val_dir = os.path.join(data_dir, 'val')\n# X_val, y_val = load_data(val_dir)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-08T14:53:51.721586Z","iopub.execute_input":"2023-04-08T14:53:51.722367Z","iopub.status.idle":"2023-04-08T14:53:51.727606Z","shell.execute_reply.started":"2023-04-08T14:53:51.722326Z","shell.execute_reply":"2023-04-08T14:53:51.726248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(os.listdir('/kaggle/input'))","metadata":{"execution":{"iopub.status.busy":"2023-04-08T14:53:58.079943Z","iopub.execute_input":"2023-04-08T14:53:58.080324Z","iopub.status.idle":"2023-04-08T14:53:58.085170Z","shell.execute_reply.started":"2023-04-08T14:53:58.080289Z","shell.execute_reply":"2023-04-08T14:53:58.083970Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom PIL import Image\nimport numpy as np\n#import tensorflow as tf\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import random_split\nimport torch\nimport wandb\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ndata_dir = '/kaggle/input/inaturalist12k/Data/inaturalist_12K'\n# #-------------------------------------------------------------------------------------------------------\n# def get_transforms(data_augmentation):\n#     if data_augmentation==\"yes\":\n#         transform = transforms.Compose([\n#             transforms.RandomHorizontalFlip(p=0.5),\n#             transforms.RandomVerticalFlip(p=0.5),\n#             transforms.RandomRotation(degrees=30),\n#             transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n#             transforms.Resize((256,256)),\n#             transforms.ToTensor()\n#         ])\n#     else:\n#         transform = transforms.Compose([\n#             transforms.Resize((256,256)),\n#             transforms.ToTensor()\n#         ])\n#     return transform\n\n# transform = transforms.Compose([transforms.Resize((256,256)),transforms.ToTensor()])\n# train_dataset=torchvision.datasets.ImageFolder(root=data_dir+'/train',transform=get_transforms(\"no\"))\n# test_dataset=torchvision.datasets.ImageFolder(root=data_dir+'/val',transform=transform)\n\n# val_size = int(len(train_dataset) * 0.2)\n# train_size = len(train_dataset) - val_size\n\n# train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n\n# train_loader=DataLoader(train_dataset,batch_size=16,shuffle=True)\n# val_loader=DataLoader(val_dataset,batch_size=16,shuffle=False)\n# test_loader=DataLoader(test_dataset,batch_size=16,shuffle=False)\n# #--------------------------------------------------------------------------------------------------------","metadata":{"execution":{"iopub.status.busy":"2023-04-10T22:12:27.695892Z","iopub.execute_input":"2023-04-10T22:12:27.696859Z","iopub.status.idle":"2023-04-10T22:12:27.705352Z","shell.execute_reply.started":"2023-04-10T22:12:27.696810Z","shell.execute_reply":"2023-04-10T22:12:27.703478Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.optim as optim\n\nimport torch.nn.functional as F\nclass Mish(nn.Module):\n    def __init__(self):\n        super().__init__()\n    def forward(self, x):\n        return x * torch.tanh(F.softplus(x))\n# Define the CNN model architecture\nclass CNN(nn.Module):\n    def __init__(self, num_filters, filter_size, activation_fn, filter_org, batch_norm, dropout,num_neuron_fc,filter_size_org):\n        super(CNN, self).__init__()\n        if(activation_fn==\"ReLU\"):\n            activation_fn=nn.ReLU\n        if(activation_fn==\"GELU\"):\n            activation_fn=nn.GELU\n        if(activation_fn==\"SiLU\"):\n            activation_fn=nn.SiLU\n        if(activation_fn==\"Mish\"):\n            activation_fn=Mish\n        if(filter_org==\"double\"):\n            filter_org=[1,2,3,4,5]\n        if(filter_org==\"same\"):\n            filter_org=[1,1,1,1,1]\n        if(filter_org==\"half\"):\n            filter_org=[1,0.5,0.5,0.5,0.5]\n        if(filter_size_org=='same'):\n            filter_size_org=[1,1,1,1,1]\n        if(filter_size_org==\"double\"):\n            filter_size_org=[1,2,2,2,2]\n        if(filter_size_org==\"half\"):\n            filter_size_org=[1,0.5,0.5,0.5,0.5]\n        layers = []\n        in_channels = 3\n        w=256\n        for i, f in enumerate(filter_org):\n            out_channels = int(num_filters * f)\n            filter_size = int(filter_size*filter_size_org[i])\n            #calculate feature map dimension\n            w=int((w-filter_size+(2*1))+1)\n            w=int(((w-2)//2)+1)\n            #ends\n            layers.append(nn.Conv2d(int(in_channels), int(out_channels), int(filter_size), padding=1))\n            if batch_norm:\n                layers.append(nn.BatchNorm2d(out_channels))\n            layers.append(activation_fn())\n            layers.append(nn.MaxPool2d(2))\n            if dropout > 0:\n                layers.append(nn.Dropout(dropout))\n            in_channels = out_channels\n        print(w)\n        self.cnn = nn.Sequential(*layers)      \n        self.fc1 = nn.Linear(int(out_channels) * w * w, num_neuron_fc)\n        self.fc2 = nn.Linear(num_neuron_fc, 10)\n\n    def forward(self, x):\n        x = self.cnn(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc1(x)\n        x = self.fc2(x)\n        return x\n\n\n\n#------------------------------------------------------------------------------------------------------\nsweep_config = {\n    'method': 'random', #grid, random,#bayes\n    'name' : 'Random_sweep_cross_entropy',\n    'metric': {\n      'name': 'valid accuracy',\n      'goal': 'maximize'  \n    },\n    'parameters': {\n        'num_filters': {\n            'values': [32,64,96]\n        },\n        'filter_size':{\n            'values':[3,5,7,2]\n        },\n         'activation_fn':{\n            'values':[\"Mish\",\"ReLU\",\"GELU\",\"SiLU\"]\n        },\n        'filter_org':{\n            'values':[\"same\",\"double\",\"half\"]\n        },\n         'filter_size_org':{\n            'values':[\"same\",\"double\"]\n        },\n         'batch_norm': {\n            'values': [True,False]\n        },\n        'dropout': {\n            'values': [0.3,0.2]\n        },\n         'num_neuron_fc':{\n            'values':[10,20]\n        },\n        'data_augmentation': {\n            'values': [\"no\",\"yes\"]\n        }, \n#         'loss': {\n#             'values': ['entropy_loss']\n#         }, \n        \n        \n    }\n}\n\nsweep_id = wandb.sweep(sweep=sweep_config, project='DL_Assign_2')\nfrom types import SimpleNamespace\ndef main():\n    with wandb.init() as run:\n        params={}\n        params=dict(wandb.config)\n        params=SimpleNamespace(**params)\n        run_name=\"num_filter_\"+str(wandb.config.num_filters)+\"-filter_size_\"+str(wandb.config.filter_size)+\"-activation_fn_\"+wandb.config.activation_fn\\\n                + \"-filter_org\"+wandb.config.filter_org+\"-filter_size_org\"+wandb.config.filter_size_org+\"-batch_norm\"+str(wandb.config.batch_norm)\\\n                + \"-dropout\"+str(wandb.config.dropout)+\"num_neuron_fc\"+str(wandb.config.num_neuron_fc)+\"-data_augmentation\"+wandb.config.data_augmentation\n        wandb.run.name=run_name\n        \n        #data augmentation function starts\n        def get_transforms(data_augmentation):\n            if data_augmentation==\"yes\":\n                transform = transforms.Compose([\n                    transforms.RandomHorizontalFlip(p=0.5),\n                    transforms.RandomVerticalFlip(p=0.5),\n                    transforms.RandomRotation(degrees=30),\n                    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n                    transforms.Resize((256,256)),\n                    transforms.ToTensor()\n                ])\n            else:\n                transform = transforms.Compose([\n                    transforms.Resize((256,256)),\n                    transforms.ToTensor()\n                ])\n            return transform\n        #data augmentation function ends\n        \n        #transform and splitting data starts\n        transform = transforms.Compose([transforms.Resize((256,256)),transforms.ToTensor()])\n        train_dataset=torchvision.datasets.ImageFolder(root=data_dir+'/train',transform=get_transforms(wandb.config.data_augmentation))\n        test_dataset=torchvision.datasets.ImageFolder(root=data_dir+'/val',transform=transform)\n\n        val_size = int(len(train_dataset) * 0.2)\n        train_size = len(train_dataset) - val_size\n\n        train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n\n        train_loader=DataLoader(train_dataset,batch_size=64,shuffle=True)\n        val_loader=DataLoader(val_dataset,batch_size=64,shuffle=False)\n        test_loader=DataLoader(test_dataset,batch_size=64,shuffle=False)\n        #transform and splitting data ends\n        \n        # Initialize the model\n        model = CNN(params.num_filters, params.filter_size, params.activation_fn, params.filter_org, params.batch_norm, params.dropout, params.num_neuron_fc,params.filter_size_org).to(device)\n\n        # Define the loss function and optimizer\n        criterion = nn.CrossEntropyLoss()\n        optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n        # Train the model\n        num_epochs = 10\n        for epoch in range(num_epochs):\n            model.train()\n            for batch_idx, (data, target) in enumerate(train_loader):\n                data, target = data.to(device), target.to(device)# Move data and target to the device\n                optimizer.zero_grad()\n                output = model(data)\n                loss = criterion(output, target)\n                loss.backward()\n                optimizer.step()\n\n            # Evaluate the model on train_loader\n            model.eval()\n            train_correct = 0\n            train_total = 0\n            train_loss = 0.0\n            with torch.no_grad():\n                for data, target in train_loader:\n                    data, target = data.to(device), target.to(device)# Move data and target to the device\n                    output = model(data)\n                    loss = criterion(output, target)\n                    train_loss += loss.item()\n                    _, predicted = torch.max(output.data, 1)\n                    train_total += target.size(0)\n                    train_correct += (predicted == target).sum().item()\n\n            train_accuracy = 100 * train_correct/train_total\n            train_loss /= len(train_loader)\n\n            # Set model to evaluation mode\n            model.eval()\n            val_loss = 0.0\n            correct = 0\n            total = 0\n            with torch.no_grad():\n                for batch_idx, (data, target) in enumerate(val_loader):\n                    data, target = data.to(device), target.to(device)# Move data and target to the device\n                    output = model(data)\n                    loss = criterion(output, target)\n                    val_loss += loss.item()\n                    _, predicted = torch.max(output.data, 1)\n                    total += target.size(0)\n                    correct += (predicted == target).sum().item()\n\n            # Calculate validation metrics\n            val_loss /= len(val_loader)\n            val_accuracy = 100 * correct / total\n\n            # Print metrics for current epoch\n            #print('Epoch: {} \\t Training Loss: {:.6f}\n            print(\"epoch\",epoch)\n            print('Training Loss: {:.6f} \\t Training Accuracy: {:.6f}'.format(train_loss, train_accuracy))\n            print('Validation Loss: {:.6f} \\t Validation Accuracy: {:.6f}'.format(val_loss, val_accuracy))\n            wandb.log({'train loss':train_loss,'train accuracy':train_accuracy,'valid loss':val_loss,'valid accuracy':val_accuracy})\n#         input_size=784\n#         output_size=10\n#         obj=neural_network(input_size,output_size,params)\n#         obj.predict()\n\n    \nwandb.agent(sweep_id, function=main,count=35)\n\n#----------------------------------------------------------------------------------------------------\n# #Define the model hyperparameters\n# num_filters = 64\n# filter_size = 3\n# activation_fn = \"ReLU\"\n# filter_org = \"half\"\n# filter_size_org=\"same\" # extra added\n# batch_norm = False\n# dropout = 0.3\n# num_neuron_fc=10\n\n\n# # Initialize the model\n# model = CNN(num_filters, filter_size, activation_fn, filter_org, batch_norm, dropout, num_neuron_fc,filter_size_org).to(device)\n\n# # Define the loss function and optimizer\n# criterion = nn.CrossEntropyLoss()\n# optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# # Train the model\n# num_epochs = 1\n# for epoch in range(num_epochs):\n#     model.train()\n#     for batch_idx, (data, target) in enumerate(train_loader):\n#         data, target = data.to(device), target.to(device)# Move data and target to the device\n#         optimizer.zero_grad()\n#         output = model(data)\n#         loss = criterion(output, target)\n#         loss.backward()\n#         optimizer.step()\n    \n#     # Evaluate the model on train_loader\n#     model.eval()\n#     train_correct = 0\n#     train_total = 0\n#     train_loss = 0.0\n#     with torch.no_grad():\n#         for data, target in train_loader:\n#             data, target = data.to(device), target.to(device)# Move data and target to the device\n#             output = model(data)\n#             loss = criterion(output, target)\n#             train_loss += loss.item()\n#             _, predicted = torch.max(output.data, 1)\n#             train_total += target.size(0)\n#             train_correct += (predicted == target).sum().item()\n\n#     train_accuracy = 100 * train_correct/train_total\n#     train_loss /= len(train_loader)\n    \n#     # Set model to evaluation mode\n#     model.eval()\n#     val_loss = 0.0\n#     correct = 0\n#     total = 0\n#     with torch.no_grad():\n#         for batch_idx, (data, target) in enumerate(val_loader):\n#             data, target = data.to(device), target.to(device)# Move data and target to the device\n#             output = model(data)\n#             loss = criterion(output, target)\n#             val_loss += loss.item()\n#             _, predicted = torch.max(output.data, 1)\n#             total += target.size(0)\n#             correct += (predicted == target).sum().item()\n            \n#     # Calculate validation metrics\n#     val_loss /= len(val_loader)\n#     val_accuracy = 100 * correct / total\n    \n#     # Print metrics for current epoch\n#     #print('Epoch: {} \\t Training Loss: {:.6f}\n#     print(\"epoch\",epoch)\n          \n#     print('Training Loss: {:.6f} \\t Training Accuracy: {:.6f}'.format(train_loss, train_accuracy))\n#     print('Validation Loss: {:.6f} \\t Validation Accuracy: {:.6f}'.format(val_loss, val_accuracy))\n\n\n\n\n\n    \n    \n    \n    \n    \n#     train_loss = 0.0\n#     for batch_idx, (data, target) in enumerate(train_loader): \n#         data, target = data.to(device), target.to(device)# Move data and target to the device\n#         optimizer.zero_grad()\n#         output = model(data)\n#         loss = criterion(output, target)\n#         loss.backward()\n#         optimizer.step()\n#         train_loss += loss.item()\n\n#     print('Epoch: {} \\t Training Loss: {:.6f}'.format(epoch+1, train_loss/len(train_loader)))\n    \n#     # Evaluate the model on train_loader\n#     model.eval()\n#     train_correct = 0\n#     train_total = 0\n#     train_loss = 0.0\n#     with torch.no_grad():\n#         for data, target in train_loader:\n#             output = model(data)\n#             loss = criterion(output, target)\n#             train_loss += loss.item()\n#             _, predicted = torch.max(output.data, 1)\n#             train_total += target.size(0)\n#             train_correct += (predicted == target).sum().item()\n\n#     train_accuracy = train_correct/train_total\n#     train_loss /= len(train_loader)\n\n#     # Evaluate the model on val_loader\n#     model.eval()\n#     val_correct = 0\n#     val_total = 0\n#     val_loss = 0.0\n#     with torch.no_grad():\n#         for data, target in val_loader:\n#             output = model(data)\n#             loss = criterion(output, target)\n#             val_loss += loss.item()\n#             _, predicted = torch.max(output.data, 1)\n#             val_total += target.size(0)\n#             val_correct += (predicted == target).sum().item()\n\n#     val_accuracy = val_correct/val_total\n#     val_loss /= len(val_loader)\n\n#     print('Training Loss: {:.6f} \\t Training Accuracy: {:.6f}'.format(train_loss, train_accuracy))\n#     print('Validation Loss: {:.6f} \\t Validation Accuracy: {:.6f}'.format(val_loss, val_accuracy))\n\n","metadata":{"execution":{"iopub.status.busy":"2023-04-10T22:12:30.682444Z","iopub.execute_input":"2023-04-10T22:12:30.682822Z","iopub.status.idle":"2023-04-10T22:25:53.046755Z","shell.execute_reply.started":"2023-04-10T22:12:30.682786Z","shell.execute_reply":"2023-04-10T22:25:53.045524Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"name":"stdout","text":"Create sweep with ID: zvzmmcmy\nSweep URL: https://wandb.ai/cs22m010/DL_Assign_2/sweeps/zvzmmcmy\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rg8vsux7 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_fn: Mish\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_augmentation: yes\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_org: same\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size_org: same\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 96\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_neuron_fc: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs22m010\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.14.2 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.14.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230410_221251-rg8vsux7</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs22m010/DL_Assign_2/runs/rg8vsux7' target=\"_blank\">golden-sweep-1</a></strong> to <a href='https://wandb.ai/cs22m010/DL_Assign_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs22m010/DL_Assign_2/sweeps/zvzmmcmy' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2/sweeps/zvzmmcmy</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs22m010/DL_Assign_2' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs22m010/DL_Assign_2/sweeps/zvzmmcmy' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2/sweeps/zvzmmcmy</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs22m010/DL_Assign_2/runs/rg8vsux7' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2/runs/rg8vsux7</a>"},"metadata":{}},{"name":"stdout","text":"6\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Control-C to abort syncing."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">golden-sweep-1</strong> at: <a href='https://wandb.ai/cs22m010/DL_Assign_2/runs/rg8vsux7' target=\"_blank\">https://wandb.ai/cs22m010/DL_Assign_2/runs/rg8vsux7</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20230410_221251-rg8vsux7/logs</code>"},"metadata":{}}]},{"cell_type":"code","source":"# import torch\n# import matplotlib.pyplot as plt\n\n# # Load an image into a PyTorch tensor\n# for i in range(1):\n#     img=train_loader[i][0].numpy().transpose((1,2,0))\n    \n# # img_tensor = torch.randn(3, 256, 256)\n\n# # # Convert the tensor to a NumPy array\n# # img = img_tensor.numpy().transpose((1, 2, 0))\n\n# plt.imshow(grid.permute(1, 2, 0))\n\n# # Display the image\n#     plt.imshow(img)\n#     plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-09T18:07:24.931478Z","iopub.execute_input":"2023-04-09T18:07:24.932180Z","iopub.status.idle":"2023-04-09T18:07:24.937175Z","shell.execute_reply.started":"2023-04-09T18:07:24.932144Z","shell.execute_reply":"2023-04-09T18:07:24.935623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import os\n# from PIL import Image\n# import numpy as np\n# #import tensorflow as tf\n# import torchvision\n# import torchvision.transforms as transforms\n# from torch.utils.data import DataLoader\n# from torch.utils.data import random_split\n# import torch\n# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# data_dir = '/kaggle/input/inaturalist12k/Data/inaturalist_12K'\n# transform = transforms.Compose([transforms.Resize((256,256)),transforms.ToTensor()])\n\n# train_dataset=torchvision.datasets.ImageFolder(root=data_dir+'/train',transform=transform)\n# test_dataset=torchvision.datasets.ImageFolder(root=data_dir+'/val',transform=transform)\n\n# val_size = int(len(train_dataset) * 0.5)\n# train_size = len(train_dataset) - val_size\n\n# train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n\n# train_loader=DataLoader(train_dataset,batch_size=64,shuffle=True)\n# val_loader=DataLoader(val_dataset,batch_size=64,shuffle=False)\n# test_loader=DataLoader(test_dataset,batch_size=64,shuffle=False)\n\n\n\n\n\n\n# import torch.nn as nn\n# import torch.optim as optim\n\n# # Define the CNN model architecture\n# class CNN(nn.Module):\n#     def __init__(self, num_filters, filter_size, activation_fn, filter_org, batch_norm, dropout):\n#         super(CNN, self).__init__()\n#         layers = []\n#         in_channels = 3\n#         for i, f in enumerate(filter_org):\n#             out_channels = num_filters * f\n#             layers.append(nn.Conv2d(in_channels, out_channels, filter_size, padding=1))\n#             if batch_norm:\n#                 layers.append(nn.BatchNorm2d(out_channels))\n#             layers.append(activation_fn())\n#             layers.append(nn.MaxPool2d(2))\n#             if dropout > 0:\n#                 layers.append(nn.Dropout(dropout))\n#             in_channels = out_channels\n#         self.cnn = nn.Sequential(*layers)\n#         self.fc = nn.Linear(out_channels * 32 * 32, 10)\n\n#     def forward(self, x):\n#         x = self.cnn(x)\n#         x = x.view(x.size(0), -1)\n#         x = self.fc(x)\n#         return x\n\n# # Define the model hyperparameters\n# num_filters = 32\n# filter_size = 3\n# activation_fn = nn.ReLU\n# filter_org = [1,2,2]\n# batch_norm = True\n# dropout = 0.3\n\n# # Initialize the model\n# model = CNN(num_filters, filter_size, activation_fn, filter_org, batch_norm, dropout).to(device)\n\n# # Define the loss function and optimizer\n# criterion = nn.CrossEntropyLoss()\n# optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# # Train the model\n# num_epochs = 5\n# for epoch in range(num_epochs):\n#     model.train()\n#     train_loss = 0.0\n#     correct = 0\n#     total = 0\n#     for batch_idx, (data, target) in enumerate(train_loader):\n#         data, target = data.to(device), target.to(device)# Move data and target to the device\n#         optimizer.zero_grad()\n#         output = model(data)\n#         loss = criterion(output, target)\n#         loss.backward()\n#         optimizer.step()\n#         train_loss += loss.item()\n#         _, predicted = torch.max(output.data, 1)\n#         total += target.size(0)\n#         correct += (predicted == target).sum().item()\n        \n#     # Calculate training metrics\n#     train_loss /= len(train_loader)\n#     train_accuracy = 100 * correct / total\n    \n#     # Set model to evaluation mode\n#     model.eval()\n#     val_loss = 0.0\n#     correct = 0\n#     total = 0\n#     with torch.no_grad():\n#         for batch_idx, (data, target) in enumerate(val_loader):\n#             data, target = data.to(device), target.to(device)# Move data and target to the device\n#             output = model(data)\n#             loss = criterion(output, target)\n#             val_loss += loss.item()\n#             _, predicted = torch.max(output.data, 1)\n#             total += target.size(0)\n#             correct += (predicted == target).sum().item()\n            \n#     # Calculate validation metrics\n#     val_loss /= len(val_loader)\n#     val_accuracy = 100 * correct / total\n    \n#     # Print metrics for current epoch\n#     #print('Epoch: {} \\t Training Loss: {:.6f}\n#     print(\"epoch\",epoch)\n          \n#     print('Training Loss: {:.6f} \\t Training Accuracy: {:.6f}'.format(train_loss, train_accuracy))\n#     print('Validation Loss: {:.6f} \\t Validation Accuracy: {:.6f}'.format(val_loss, val_accuracy))\n\n\n\n\n\n    \n    \n    \n    \n    \n# #     train_loss = 0.0\n# #     for batch_idx, (data, target) in enumerate(train_loader): \n# #         data, target = data.to(device), target.to(device)# Move data and target to the device\n# #         optimizer.zero_grad()\n# #         output = model(data)\n# #         loss = criterion(output, target)\n# #         loss.backward()\n# #         optimizer.step()\n# #         train_loss += loss.item()\n\n# #     print('Epoch: {} \\t Training Loss: {:.6f}'.format(epoch+1, train_loss/len(train_loader)))\n    \n# #     # Evaluate the model on train_loader\n# #     model.eval()\n# #     train_correct = 0\n# #     train_total = 0\n# #     train_loss = 0.0\n# #     with torch.no_grad():\n# #         for data, target in train_loader:\n# #             output = model(data)\n# #             loss = criterion(output, target)\n# #             train_loss += loss.item()\n# #             _, predicted = torch.max(output.data, 1)\n# #             train_total += target.size(0)\n# #             train_correct += (predicted == target).sum().item()\n\n# #     train_accuracy = train_correct/train_total\n# #     train_loss /= len(train_loader)\n\n# #     # Evaluate the model on val_loader\n# #     model.eval()\n# #     val_correct = 0\n# #     val_total = 0\n# #     val_loss = 0.0\n# #     with torch.no_grad():\n# #         for data, target in val_loader:\n# #             output = model(data)\n# #             loss = criterion(output, target)\n# #             val_loss += loss.item()\n# #             _, predicted = torch.max(output.data, 1)\n# #             val_total += target.size(0)\n# #             val_correct += (predicted == target).sum().item()\n\n# #     val_accuracy = val_correct/val_total\n# #     val_loss /= len(val_loader)\n\n# #     print('Training Loss: {:.6f} \\t Training Accuracy: {:.6f}'.format(train_loss, train_accuracy))\n# #     print('Validation Loss: {:.6f} \\t Validation Accuracy: {:.6f}'.format(val_loss, val_accuracy))\n\n","metadata":{"execution":{"iopub.status.busy":"2023-04-08T15:37:56.476412Z","iopub.execute_input":"2023-04-08T15:37:56.476829Z","iopub.status.idle":"2023-04-08T15:37:58.123794Z","shell.execute_reply.started":"2023-04-08T15:37:56.476794Z","shell.execute_reply":"2023-04-08T15:37:58.122340Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}